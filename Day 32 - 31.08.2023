Apache Spark - core technology for large-scale data analytics. Learn how to use Spark in ASA to analyse and visualise data in data lake.

It is important to remember that Apache Spark is a open source parallel processing framework for large-scale data processing and analytics. It has become 
extremely popular in big data processing scenarios, and is available in multiple platform implementations.

This includes:

Azure HDInishgt
Azure Datatricks
Azure Synapse Analytics

The purpose of this module is to use Spark in ASA to ingest, process and analyse data from a data lake. 

1) Identify the core features and capabilities of Apache Spark.
2) Configure a Spark pool in Azure Synapse Analytics
3) Run code to load, analyse and visualise data in a Spark notebook.

https://learn.microsoft.com/en-gb/training/modules/understand-big-data-engineering-with-apache-spark-azure-synapse-analytics/2-get-to-know-spark

https://learn.microsoft.com/en-gb/training/modules/understand-big-data-engineering-with-apache-spark-azure-synapse-analytics/3-use-spark


