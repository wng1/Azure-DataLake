Many enterprise analytical solutions includea a relational data warehouse. Data engineers are responsible for implementing ingestion solutiosn that load into data warehouse tables, usually on a regular schedule.
As a data engineer, you need to be familiar with the considerations and techniques that apply to loading a data warehouse. In this module, we'll focus on ways that you can use SQL to load data into tables in a dedicated SQL pool in Azure Synapse Analytics.

Load Staging Tables
CREATE TABLE dbo.StageProduct
(
    ProductID NVARCHAR(10) NOT NULL,
    ProductName NVARCHAR(200) NOT NULL,
    ProductCategory NVARCHAR(200) NOT NULL,
    Color NVARCHAR(10),
    Size NVARCHAR(10),
    ListPrice DECIMAL NOT NULL,
    Discontinued BIT NOT NULL
)
WITH
(
    DISTRIBUTION = ROUND_ROBIN,
    CLUSTERED COLUMNSTORE INDEX
);

COPY INTO dbo.StageProduct
	(ProductID, ProductName, ....)
FROM 'htttp............./data/products*.parquet'
WITH
(
	FILE_TYPE = 'PARQUET'
	MAXERRORS = 0,
	IDENTITY_INSERT = 'OFF'
);

Using external tables

In some cases, if the data to be loaded is stored in files with an appropriate strucute, it can more effective to create external tables that reference the file location. This way, the data can be read directly from the source files instead of being loaded into the relational store. 
The following example, shows how to create an external table that reference files in the data lake associated with the Azure Synpase Analytics workspace.

CREATE TABLE dbo.DimProduct
WITH 
( 
	DISTRIBUTION = REPLICATE,
	CLUSTERED COLUMNSTORE INDEX
)
AS
SELECT ROW_NUMBER() OVER (ORDER BY ProdID) As ProdKey,
	ProdID as ProdAltKey,
	ProductName,
	ProductCategory,
	Color,
	Size,
	ListPrice,
	Discontinued
FROM dbo.StageProduct;


CREATE TABLE dbo.DimProducerUpsert

WITH
(
	DISTRIBUTION = REPLICATE,
	CLUSTERED COLUMNSTORE INDEX
AS
SELECT  stg.ProductID AS ProductBusinessKey,
        stg.ProductName,
        stg.ProductCategory,
        stg.Color,
        stg.Size,
        stg.ListPrice,
        stg.Discontinued
FROM    dbo.StageProduct AS stg
UNION ALL  
SELECT  dim.ProductBusinessKey,
        dim.ProductName,
        dim.ProductCategory,
        dim.Color,
        dim.Size,
        dim.ListPrice,
        dim.Discontinued
FROM    dbo.DimProduct AS dim
WHERE NOT EXISTS
(   SELECT  *
    FROM dbo.StageProduct AS stg
    WHERE stg.ProductId = dim.ProductBusinessKey
);
RENAME OBJECT dbo.DimProduct TO DimProductArchive;
RENAME OBJECT dbo.DimProductUpsert TO DimProduct;

**
You can also load a combination of new and updated data into a dimension table by using a CREATE TABLE AS (CTAS) statement to create a new table that UNIONs the existing rows from the dimension table with the new and update records from the staging table.

After creating the new table, you can delete or rename the current dimension table, and rename the new table to replace it.

While this technique is effective in merging new and existing dimension data, lack of support for IDENTITY columns means that it's difficult to generate a surrogate key.

------------------------------------------------------------------------------------------------

When you need to load staged data into an existing dimension table, you can use an INSERT statement. This approach works if the staged data contains only records for new dimension entities (not updates to existing entities). This approach is much less complicated than the technique in the last section, which required a UNION ALL and then renaming table objects.


-------------------------------------------------------------------------------------------------
Using an INSERT statement

INSERT INTO dbo.DimCustomer
SELECT CustomerNo AS CustAltKey,
    CustomerName,
    EmailAddress,
    Phone,
    StreetAddress,
    City,
    PostalCode,
    CountryRegion
FROM dbo.StageCustomers

When you need to load staged data into an existing dimension table, you can use an INSERT statement. This approach works if the staged data contains only records for new dimension entities (not updates to existing entities). This approach is much less complicated than the technique in the last section, which required a UNION ALL and then renaming table objects.

--------------------------------------------------------------------------------------------------------------
Assuming the DimCustomer dimension table is defined with an IDENTITY CustomerKey column for the surrogate key (as described in the previous unit), the key will be generated automatically and the remaining columns will be populated using the values retrieved from the staging table by the SELECT query.
--------------------------------------------------------------------------------------------------------------

Load time dimension tables

-- Create a temporary table for the dates we need
CREATE TABLE #TmpStageDate (DateVal DATE NOT NULL)

-- Populate the temp table with a range of dates
DECLARE @StartDate DATE
DECLARE @EndDate DATE
SET @StartDate = '2019-01-01'
SET @EndDate = '2023-12-31'
DECLARE @LoopDate = @StartDate
WHILE @LoopDate <= @EndDate
BEGIN
    INSERT INTO #TmpStageDate VALUES
    (
        @LoopDate
    )
    SET @LoopDate = DATEADD(dd, 1, @LoopDate)
END

-- Insert the dates and calculated attributes into the dimension table
INSERT INTO dbo.DimDate
SELECT CAST(CONVERT(VARCHAR(8), DateVal, 112) as INT), -- date key
    DateVal, --date alt key
    Day(DateVal) -- day number of month
    --,  other derived temporal fields as required
FROM #TmpStageDate
GO

--Drop temporary table
DROP TABLE #TmpStageDate

-----------
Scripting this in SQL may be time-consuming in a dedicated SQL pool â€“ it may be more efficient to prepare the data in Microsoft Excel or an external script and import it using the COPY statement.


As the data warehouse is populated in the future with new fact data, you periodically need to extend the range of dates related time dimension tables.

-----------

Load slowly changing dimensions

https://learn.microsoft.com/en-gb/training/modules/load-optimize-data-into-relational-data-warehouse/5-load-slowly-changing-dimensions

Load fact tables
Post Load Optimization
Perform Post Load Optimization



