##Query data in a relational data warehouse

If you used the output of ASA to ingest the results of your stream processing job into a table in a dedicated SQL pool,
you can query the table using SQL query highlighted below. 

The results of the query will always include the latest data to be ingested at the time the query is run.

Your datawarehouse can include tables for streaming data as well as table for batch ingested data, enabling you to join
real-time and batch data for historical analytics.


This will query a table called factSensorReadings that contains the results of stream processing, and combine it with dimDate Table
containing detailed data about the dates on which readings were captured.


SELECT d.Weekday, s.SensorID, AVG(s.SensorReading) AS AverageReading
FROM factSensorReading AS s
JOIN dimDate AS d
  ON CAST (s.ReadingTime AS DATE) = d.DateKey
GROUP BY d.Weekday, s.SensorID

## Querying data in a data lake

As streaming data is ingested into files in a data lake, you can query those files by using a serverless SQL pool
in Azure Synapse Analytics. 

For examples, the below query will read all fields from all Parquet files under the sensors folder in the
data file system container.

SELECT *
FROM OPENROWSET(
  BULK '________________________________/*',
  FORMAT = 'parquet' AS rows

##https://learn.microsoft.com/en-gb/training/modules/ingest-streaming-data-use-azure-stream-analytics-synapse/5-run-job-ingest


##Python

%%pyspark

df = spark.read.load('__________________________/*', format='parquet'
)
display(df)

##https://learn.microsoft.com/en-gb/training/module/ingest-streaming-data-use-azure-stream-analytics-synapse/6-exercise-ingest-streaming-data

